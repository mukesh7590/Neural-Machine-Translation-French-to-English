{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_french_english.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neV9LtQClr15"
      },
      "source": [
        "# Project : French to English "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXe0Bo9aIyY5"
      },
      "source": [
        "!wget http://www.manythings.org/anki/fra-eng.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-CmVd9eJF5q"
      },
      "source": [
        "# Opening the DataSet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnTQWeF9I4xm"
      },
      "source": [
        "!unzip ./fra-eng.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr0LC2DfJWTf"
      },
      "source": [
        "# Importing the important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWHDoViaJU0k"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Input,Embedding,TimeDistributed,RepeatVector\n",
        "from nltk.translate.bleu_score import SmoothingFunction,corpus_bleu\n",
        "smoothie = SmoothingFunction().method4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2zZH12eJreX"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKCrhjq5JU4b"
      },
      "source": [
        "data_path = './fra.txt' # path of the file\n",
        "num_sentences = 20000 # no of sentences from the dataset that we are going to use\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_QHOoSKJ9XJ"
      },
      "source": [
        "# opening the text file and getting the data \n",
        "with open(data_path,'r') as f:\n",
        "    lines = f.read().split('\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oVYLU1uKE3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8ae37a-1e2e-43f6-9e2e-6209686d7f3d"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190207"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfAhKrE0KVp3"
      },
      "source": [
        "c=0 # for to count the number of sentences\n",
        "\n",
        "\n",
        "# data cleaning\n",
        "\n",
        "source_texts,target_texts = [],[]\n",
        "for line in lines: # going through each lines\n",
        "    if c == num_sentences: # if we have 20000 sentences than we will get out of this loop\n",
        "        break \n",
        "    elif '\\t' in line:\n",
        "        op_data,ip_data,_ = line.lower().rstrip().split('\\t') # lowering the data and then spliting the data\n",
        "        \n",
        "        # to remove the punctuation we did not include last character\n",
        "        source_text = ip_data[:-1].strip()\n",
        "        target_text = op_data[:-1].strip()\n",
        "        # removing the unprintable character\n",
        "        # for english and french we will take anly alphabets of brespective languages and numbers\n",
        "        target_text = re.sub(\"[^a-z 1-9\\'-]\",\"\",target_text) \n",
        "        source_text = re.sub(\"[^a-zàâãçéèêëîïôœùûüÿ 1-9\\'-]\",\"\",source_text) \n",
        "        \n",
        "        source_texts.append(source_text)\n",
        "        target_texts.append(target_text)\n",
        "        c+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ktD5XJLOlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a8da86-00b0-49fb-f1b1-ca0783429313"
      },
      "source": [
        "for i in range(10):\n",
        "    print(source_texts[i] + \" \" + target_texts[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "va go\n",
            "marche go\n",
            "bouge go\n",
            "salut hi\n",
            "salut hi\n",
            "cours run\n",
            "courez run\n",
            "prenez vos jambes à vos cous run\n",
            "file run\n",
            "filez run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEHifNJcJU8T"
      },
      "source": [
        "# train_test_split of the source and target data\n",
        "source_train,source_test,target_train,target_test = train_test_split(source_texts,target_texts,test_size = 0.2, random_state= 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKpzFVmTMzxc"
      },
      "source": [
        "# Making required function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0NA1XTFJVAi"
      },
      "source": [
        "# tokenizer for data\n",
        "def create_tokenizer(texts):\n",
        "    tokenizer = Tokenizer(oov_token='<UNK>')\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    return tokenizer\n",
        "\n",
        "# one_hot encoding of the target data\n",
        "def one_hot(pad_seq,max_sent_length,num_vocab):\n",
        "    target_data_one_hot = np.zeros((len(pad_seq),max_sent_length,num_vocab))\n",
        "    for i,w in enumerate(pad_seq):\n",
        "        for j,d in enumerate(w):\n",
        "            target_data_one_hot[i,j,d] = 1\n",
        "    return target_data_one_hot\n",
        "\n",
        "# for padding the data\n",
        "def encoding_text(tokenizer,text,max_length):\n",
        "    text_seq = tokenizer.texts_to_sequences(text)\n",
        "    pad_seq = pad_sequences(text_seq,maxlen= max_length)\n",
        "    return pad_seq\n",
        "\n",
        "# to find the maximum length of the sentence from data\n",
        "def max_length(text):\n",
        "    return max(len(l.split()) for l in text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usqk-MqkNKwd"
      },
      "source": [
        "# Preparing Training and Testing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pGcq-kMJVEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38819bb0-fedf-4d7d-dd6f-926b23e0a2fb"
      },
      "source": [
        "# preparing source tokenizer and getting relevant information\n",
        "source_tokenizer = create_tokenizer(source_train)\n",
        "source_vocab = source_tokenizer.word_index\n",
        "num_source_vocab = len(source_vocab)+1\n",
        "max_source_length = max_length(source_train)\n",
        "\n",
        "# preparing target tokenizer and getting relevant information\n",
        "target_tokenizer = create_tokenizer(target_train)\n",
        "target_vocab = target_tokenizer.word_index\n",
        "num_target_vocab = len(target_vocab)+1\n",
        "max_target_length = max_length(target_train)\n",
        "\n",
        "# preparing the training data\n",
        "source_train_seq_pad = encoding_text(source_tokenizer,source_train,max_source_length) # padding of the source sentences\n",
        "target_train_seq_pad = encoding_text(target_tokenizer,target_train,max_target_length) # padding of the target sentences\n",
        "target_train_seq_pad = one_hot(target_train_seq_pad,max_target_length,num_target_vocab) # one hot encoding of the padded target senteces\n",
        "\n",
        "# preparing the test data\n",
        "source_test_seq_pad = encoding_text(source_tokenizer,source_test,max_source_length) # padding of the source sentences\n",
        "target_test_seq_pad = encoding_text(target_tokenizer,target_test,max_target_length) # padding of the target sentences\n",
        "target_test_seq_pad = one_hot(target_test_seq_pad,max_target_length,num_target_vocab) # one hot encoding of the padded target senteces\n",
        " \n",
        "print(num_source_vocab,num_target_vocab,max_source_length,max_target_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5969 3189 11 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu_7XEtbJVID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5f2926-9a7c-4e17-c40e-616fe7463ddd"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(max_source_length,)))\n",
        "model.add(Embedding(num_source_vocab,512,mask_zero=True))\n",
        "model.add(LSTM(512,return_sequences = False))\n",
        "model.add(RepeatVector(max_target_length))\n",
        "model.add(LSTM(512,return_sequences = True))\n",
        "model.add(TimeDistributed(Dense(num_target_vocab,activation = 'softmax')))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 11, 512)           3056128   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 5, 512)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 5, 512)            2099200   \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 5, 3189)           1635957   \n",
            "=================================================================\n",
            "Total params: 8,890,485\n",
            "Trainable params: 8,890,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruH2_sszH6zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cd9857-7259-4326-c2ef-7c4954ff71e6"
      },
      "source": [
        "es = EarlyStopping(monitor='val_acc',patience= 5,min_delta=0.01) # EarlyStoping callback to stop the fitting before all epochs\n",
        "filepath = './fre2eng.h5' # filepath required for checkpoint\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max') # ModelCheckPoint to save the best model\n",
        "\n",
        "history = model.fit(source_train_seq_pad, target_train_seq_pad, \n",
        "                    epochs= 50,\n",
        "                    batch_size=128, \n",
        "                    validation_data = (source_test_seq_pad,target_test_seq_pad), \n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint,es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 20s 82ms/step - loss: 3.9635 - acc: 0.4121 - val_loss: 3.5720 - val_acc: 0.4278\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.42780, saving model to ./fre2eng.h5\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 3.4056 - acc: 0.4392 - val_loss: 3.3135 - val_acc: 0.4569\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.42780 to 0.45690, saving model to ./fre2eng.h5\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 3.0693 - acc: 0.4743 - val_loss: 3.0107 - val_acc: 0.4943\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.45690 to 0.49435, saving model to ./fre2eng.h5\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 2.7656 - acc: 0.5078 - val_loss: 2.7719 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.49435 to 0.51845, saving model to ./fre2eng.h5\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 2.5141 - acc: 0.5393 - val_loss: 2.6269 - val_acc: 0.5437\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.51845 to 0.54370, saving model to ./fre2eng.h5\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 9s 68ms/step - loss: 2.3038 - acc: 0.5659 - val_loss: 2.4933 - val_acc: 0.5595\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.54370 to 0.55955, saving model to ./fre2eng.h5\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 2.1216 - acc: 0.5900 - val_loss: 2.3670 - val_acc: 0.5782\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.55955 to 0.57820, saving model to ./fre2eng.h5\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 1.9503 - acc: 0.6119 - val_loss: 2.2662 - val_acc: 0.5982\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.57820 to 0.59825, saving model to ./fre2eng.h5\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 1.7877 - acc: 0.6365 - val_loss: 2.1837 - val_acc: 0.6076\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.59825 to 0.60755, saving model to ./fre2eng.h5\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 1.6368 - acc: 0.6596 - val_loss: 2.1244 - val_acc: 0.6159\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.60755 to 0.61590, saving model to ./fre2eng.h5\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 1.4956 - acc: 0.6819 - val_loss: 2.0620 - val_acc: 0.6331\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.61590 to 0.63305, saving model to ./fre2eng.h5\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 1.3622 - acc: 0.7056 - val_loss: 2.0096 - val_acc: 0.6391\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.63305 to 0.63910, saving model to ./fre2eng.h5\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 1.2384 - acc: 0.7286 - val_loss: 1.9701 - val_acc: 0.6483\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.63910 to 0.64830, saving model to ./fre2eng.h5\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 1.1189 - acc: 0.7502 - val_loss: 1.9191 - val_acc: 0.6626\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.64830 to 0.66260, saving model to ./fre2eng.h5\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 1.0106 - acc: 0.7728 - val_loss: 1.8932 - val_acc: 0.6671\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.66260 to 0.66705, saving model to ./fre2eng.h5\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.9099 - acc: 0.7930 - val_loss: 1.8674 - val_acc: 0.6728\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.66705 to 0.67280, saving model to ./fre2eng.h5\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.8146 - acc: 0.8140 - val_loss: 1.8346 - val_acc: 0.6813\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.67280 to 0.68135, saving model to ./fre2eng.h5\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.7272 - acc: 0.8312 - val_loss: 1.8287 - val_acc: 0.6852\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.68135 to 0.68515, saving model to ./fre2eng.h5\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.6486 - acc: 0.8486 - val_loss: 1.8039 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.68515 to 0.68980, saving model to ./fre2eng.h5\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.5816 - acc: 0.8612 - val_loss: 1.7971 - val_acc: 0.6936\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.68980 to 0.69360, saving model to ./fre2eng.h5\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.5198 - acc: 0.8750 - val_loss: 1.7994 - val_acc: 0.6931\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.69360\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.4649 - acc: 0.8875 - val_loss: 1.7917 - val_acc: 0.6957\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.69360 to 0.69575, saving model to ./fre2eng.h5\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.4173 - acc: 0.8978 - val_loss: 1.7913 - val_acc: 0.7030\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.69575 to 0.70295, saving model to ./fre2eng.h5\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3748 - acc: 0.9068 - val_loss: 1.7915 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.70295 to 0.70440, saving model to ./fre2eng.h5\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.3371 - acc: 0.9152 - val_loss: 1.8096 - val_acc: 0.6999\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.70440\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3055 - acc: 0.9213 - val_loss: 1.8059 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.70440 to 0.70645, saving model to ./fre2eng.h5\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 8s 68ms/step - loss: 0.2775 - acc: 0.9270 - val_loss: 1.8162 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.70645 to 0.71070, saving model to ./fre2eng.h5\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.2541 - acc: 0.9308 - val_loss: 1.8136 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.71070 to 0.71160, saving model to ./fre2eng.h5\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.2327 - acc: 0.9357 - val_loss: 1.8354 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.71160\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.2179 - acc: 0.9381 - val_loss: 1.8468 - val_acc: 0.7087\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.71160\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.2032 - acc: 0.9398 - val_loss: 1.8517 - val_acc: 0.7117\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.71160 to 0.71175, saving model to ./fre2eng.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLqPWu8nJVMg"
      },
      "source": [
        "# loading the weights from the best saved model\n",
        "model.load_weights(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySLwwiYEJVQb"
      },
      "source": [
        "# a dictionary having key is a token number for a particular word and value is a word\n",
        "# this will required to decode the predicted sequence\n",
        "target_vocab_idx = {v:k for k,v in target_tokenizer.word_index.items()}\n",
        "\n",
        "# function to predict the decoded sequence\n",
        "def predict_sequence(model,sent,vocab_idx):\n",
        "    prediction = model.predict(sent.reshape(1,max_source_length))[0]\n",
        "    integers = [np.argmax(vector) for vector in prediction]\n",
        "    target = []\n",
        "    for i in integers:\n",
        "        if i != 0:\n",
        "            word = vocab_idx[i]\n",
        "            if word is None:\n",
        "                break\n",
        "            target.append(word)\n",
        "            \n",
        "    return ' '.join(target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8phO08noJVUn"
      },
      "source": [
        "# for evaluation of the model through BLEU_score\n",
        "def bleu_score(model,ip,ip_raw,op_raw,vocab_idx):\n",
        "    \n",
        "    prediction,actual = [],[]\n",
        "    for i,sent in enumerate(ip):\n",
        "        \n",
        "        if i%10 == 0: # to print the progress\n",
        "            print('\\rprogress ',(i+1)*100//len(ip),'%',sep='',end='',flush = True)\n",
        "        \n",
        "        translation = predict_sequence(model,sent,vocab_idx)\n",
        "        \n",
        "        prediction.append(translation)\n",
        "        actual.append(op_raw[i])\n",
        "    \n",
        "    print()\n",
        "    # printing the first ten sentences\n",
        "    for i in range(10):\n",
        "        print('French_sentence -',ip_raw[i],' | ',\n",
        "            'English_actual_sentence -',op_raw[i],' | ',\n",
        "            'English_predicted_sentence -',prediction[i])\n",
        "    \n",
        "    print()\n",
        "    # printing the BLEU_score\n",
        "    print('BLEU_SCORE')\n",
        "    print('BLEU score-1: %f' % corpus_bleu(actual, prediction, weights=(1.0, 0, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
        "    print('BLEU score-2: %f' % corpus_bleu(actual, prediction, weights=(0.5, 0.5, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
        "    print('BLEU score-3: %f' % corpus_bleu(actual, prediction, weights=(0.3, 0.3, 0.3, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
        "    print('BLEU score-4: %f' % corpus_bleu(actual, prediction, weights=(0.25, 0.25, 0.25, 0.25),smoothing_function=smoothie,auto_reweigh=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRs7niIalpRJ"
      },
      "source": [
        "# Evaluating the model on training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQjTSc_NuDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e044ae5-c81f-47a0-a9b1-815501afe9b6"
      },
      "source": [
        "bleu_score(model,source_train_seq_pad,source_train,target_train,target_vocab_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress 99%\n",
            "French_sentence - que vous êtes grandes  |  English_actual_sentence - how tall you are  |  English_predicted_sentence - how tall you are\n",
            "French_sentence - j'ai rencontré mes amis  |  English_actual_sentence - i met my friends  |  English_predicted_sentence - i met my friends\n",
            "French_sentence - restez assis sans bouger  |  English_actual_sentence - sit still  |  English_predicted_sentence - sit still\n",
            "French_sentence - fais-en simplement l'expérience  |  English_actual_sentence - just try it out  |  English_predicted_sentence - just try it out\n",
            "French_sentence - j'utilise firefox  |  English_actual_sentence - i use firefox  |  English_predicted_sentence - i use firefox\n",
            "French_sentence - demande de l'aide  |  English_actual_sentence - call for help  |  English_predicted_sentence - call for help\n",
            "French_sentence - garez-vous s'il vous plaît  |  English_actual_sentence - please pull over  |  English_predicted_sentence - please pull over\n",
            "French_sentence - quelqu'un rigola  |  English_actual_sentence - somebody laughed  |  English_predicted_sentence - somebody laughed\n",
            "French_sentence - vous avez l'air en colère  |  English_actual_sentence - you sound angry  |  English_predicted_sentence - you sound angry\n",
            "French_sentence - nous devons aider  |  English_actual_sentence - we must help  |  English_predicted_sentence - we we must help\n",
            "\n",
            "BLEU_SCORE\n",
            "BLEU score-1: 0.712845\n",
            "BLEU score-2: 0.480683\n",
            "BLEU score-3: 0.422428\n",
            "BLEU score-4: 0.324751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjMTzfKZWxEm"
      },
      "source": [
        "# Evaluating the model on testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeE_WHIRNuJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9357c4c-a1d2-4d84-a7a1-67cbd335afd6"
      },
      "source": [
        "\n",
        "bleu_score(model,source_test_seq_pad,source_test,target_test,target_vocab_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress 99%\n",
            "French_sentence - ce n'était pas une course  |  English_actual_sentence - it wasn't a race  |  English_predicted_sentence - it didn't a bike\n",
            "French_sentence - je me suis dégonflée  |  English_actual_sentence - i wimped out  |  English_predicted_sentence - i got american\n",
            "French_sentence - vous êtes créatives  |  English_actual_sentence - you're creative  |  English_predicted_sentence - you're silly\n",
            "French_sentence - c'était nécessaire  |  English_actual_sentence - it was necessary  |  English_predicted_sentence - that was stupid\n",
            "French_sentence - c'était vague  |  English_actual_sentence - it was vague  |  English_predicted_sentence - it was likes enticing\n",
            "French_sentence - oust  |  English_actual_sentence - get out  |  English_predicted_sentence - get out\n",
            "French_sentence - je me suis remise  |  English_actual_sentence - i recovered  |  English_predicted_sentence - i recovered\n",
            "French_sentence - elles travaillent toutes les deux  |  English_actual_sentence - they both work  |  English_predicted_sentence - they both up\n",
            "French_sentence - j'ai eu une mauvaise journée  |  English_actual_sentence - i had a bad day  |  English_predicted_sentence - i had a hard day\n",
            "French_sentence - es-tu debout  |  English_actual_sentence - are you up  |  English_predicted_sentence - are you up\n",
            "\n",
            "BLEU_SCORE\n",
            "BLEU score-1: 0.583643\n",
            "BLEU score-2: 0.444846\n",
            "BLEU score-3: 0.407350\n",
            "BLEU score-4: 0.317202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHlAL1DiNuQ0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCcJo0b0NuX1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7G68OG4Nubc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLessZjsNum1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKRJw9RBJVaT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCD7UMmXJVft"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBLG3_ggI9Cc"
      },
      "source": [
        ""
      ]
    }
  ]
}